{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer  # Ensure SimpleImputer is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 891)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-import necessary library after environment reset\n",
    "import pandas as pd\n",
    "\n",
    "# File path for the Titanic dataset\n",
    "file_path = '/Users/manuel/Desktop/DI-Bootcamp/Week4_PreProcessing_Data/D4/ExerciseXP/Titanic/train.csv'\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic_df = pd.read_csv(file_path)\n",
    "print(titanic_df.head())\n",
    "\n",
    "# Check the number of rows before removing duplicates\n",
    "rows_before = len(titanic_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 891)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify duplicates based on all columns\n",
    "duplicates = titanic_df.duplicated()\n",
    "duplicates\n",
    "\n",
    "# Remove duplicate rows\n",
    "titanic_df_cleaned = titanic_df.drop_duplicates()\n",
    "titanic_df_cleaned\n",
    "\n",
    "# Check the number of rows after removing duplicates\n",
    "rows_after = len(titanic_df_cleaned)\n",
    "print(rows_after)\n",
    "\n",
    "# Display the number of rows before and after duplicate removal\n",
    "(rows_before, rows_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PassengerId      0\n",
       " Survived         0\n",
       " Pclass           0\n",
       " Name             0\n",
       " Sex              0\n",
       " Age            177\n",
       " SibSp            0\n",
       " Parch            0\n",
       " Ticket           0\n",
       " Fare             0\n",
       " Cabin          687\n",
       " Embarked         2\n",
       " dtype: int64,\n",
       " (204, 12),\n",
       " np.int64(0),\n",
       " np.int64(0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 2: Handling Missing Values\n",
    "\n",
    "# Step 1: Identify columns with missing values\n",
    "missing_values = titanic_df.isnull().sum()\n",
    "\n",
    "# Step 2: Apply different strategies for handling missing data\n",
    "\n",
    "# Strategy 1: Remove rows with missing 'Cabin' data\n",
    "titanic_dropna = titanic_df.dropna(subset=['Cabin'])\n",
    "#print(titanic_dropna)\n",
    "\n",
    "# Strategy 2: Fill missing 'Age' values with the median\n",
    "titanic_fillna_age = titanic_df.copy()\n",
    "titanic_fillna_age['Age'] = titanic_fillna_age['Age'].fillna(titanic_fillna_age['Age'].median())\n",
    "\n",
    "# Strategy 3: Use SimpleImputer to fill missing 'Embarked' values with the most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "titanic_imputed_embarked = titanic_df.copy()\n",
    "titanic_imputed_embarked['Embarked'] = imputer.fit_transform(titanic_imputed_embarked[['Embarked']]).ravel()\n",
    "\n",
    "# Display the results of missing value handling\n",
    "missing_values, titanic_dropna.shape, titanic_fillna_age['Age'].isnull().sum(), titanic_imputed_embarked['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin  FamilySize Title  Sex_encoded  \\\n",
      "0      0         A/5 21171   7.2500   NaN           2    Mr            1   \n",
      "1      0          PC 17599  71.2833   C85           2   Mrs            0   \n",
      "2      0  STON/O2. 3101282   7.9250   NaN           1  Miss            0   \n",
      "3      0            113803  53.1000  C123           2   Mrs            0   \n",
      "4      0            373450   8.0500   NaN           1    Mr            1   \n",
      "\n",
      "   Embarked_C  Embarked_Q  Embarked_S  Age_scaled  Fare_scaled  \n",
      "0       False       False        True   -0.530377    -0.502445  \n",
      "1        True       False       False    0.571831     0.786845  \n",
      "2       False       False        True   -0.254825    -0.488854  \n",
      "3       False       False        True    0.365167     0.420730  \n",
      "4       False       False        True    0.365167    -0.486337  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the Titanic dataset\n",
    "file_path = '/Users/manuel/Desktop/DI-Bootcamp/Week4_PreProcessing_Data/D4/ExerciseXP/Titanic/train.csv'\n",
    "titanic_df = pd.read_csv(file_path)\n",
    "\n",
    "# Exercise 3: Feature Engineering\n",
    "\n",
    "# Step 1: Create new features\n",
    "\n",
    "# Create 'FamilySize' from 'SibSp' (Number of siblings/spouses aboard) and 'Parch' (Number of parents/children aboard)\n",
    "titanic_df['FamilySize'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1  # +1 to include the passenger themselves\n",
    "\n",
    "# Extract 'Title' from the 'Name' column\n",
    "titanic_df['Title'] = titanic_df['Name'].apply(lambda name: name.split(', ')[1].split('.')[0])\n",
    "\n",
    "# Step 2: Convert categorical variables into numerical form\n",
    "\n",
    "# Convert 'Sex' to numerical form using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "titanic_df['Sex_encoded'] = label_encoder.fit_transform(titanic_df['Sex'])\n",
    "\n",
    "# One-hot encode 'Embarked' column\n",
    "titanic_df = pd.get_dummies(titanic_df, columns=['Embarked'], prefix='Embarked')\n",
    "\n",
    "# Step 3: Normalize or standardize numerical features if required\n",
    "\n",
    "# Standardize 'Age' and 'Fare' using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "titanic_df[['Age_scaled', 'Fare_scaled']] = scaler.fit_transform(titanic_df[['Age', 'Fare']])\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(titanic_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116, 11), (0, 0))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Titanic dataset\n",
    "file_path = '/Users/manuel/Desktop/DI-Bootcamp/Week4_PreProcessing_Data/D4/ExerciseXP/Titanic/train.csv'\n",
    "titanic_df = pd.read_csv(file_path)\n",
    "\n",
    "# Exercise 4: Outlier Detection and Handling\n",
    "\n",
    "# Step 1: Detect outliers using IQR (Interquartile Range) for 'Fare' and 'Age'\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for 'Fare' and 'Age'\n",
    "Q1_fare = titanic_df['Fare'].quantile(0.25)\n",
    "Q3_fare = titanic_df['Fare'].quantile(0.75)\n",
    "IQR_fare = Q3_fare - Q1_fare\n",
    "\n",
    "Q1_age = titanic_df['Age'].quantile(0.25)\n",
    "Q3_age = titanic_df['Age'].quantile(0.75)\n",
    "IQR_age = Q3_age - Q1_age\n",
    "\n",
    "# Define outlier thresholds for 'Fare' and 'Age'\n",
    "fare_lower_bound = Q1_fare - 1.5 * IQR_fare\n",
    "fare_upper_bound = Q3_fare + 1.5 * IQR_fare\n",
    "\n",
    "age_lower_bound = Q1_age - 1.5 * IQR_age\n",
    "age_upper_bound = Q3_age + 1.5 * IQR_age\n",
    "\n",
    "# Identify outliers in 'Fare' and 'Age'\n",
    "fare_outliers = titanic_df[(titanic_df['Fare'] < fare_lower_bound) | (titanic_df['Fare'] > fare_upper_bound)]\n",
    "age_outliers = titanic_df[(titanic_df['Age'] < age_lower_bound) | (titanic_df['Age'] > age_upper_bound)]\n",
    "\n",
    "# Step 2: Handle the outliers\n",
    "\n",
    "# Strategy: Capping the outliers to the upper and lower bounds\n",
    "titanic_df['Fare'] = np.where(titanic_df['Fare'] > fare_upper_bound, fare_upper_bound, \n",
    "                              np.where(titanic_df['Fare'] < fare_lower_bound, fare_lower_bound, titanic_df['Fare']))\n",
    "\n",
    "titanic_df['Age'] = np.where(titanic_df['Age'] > age_upper_bound, age_upper_bound, \n",
    "                             np.where(titanic_df['Age'] < age_lower_bound, age_lower_bound, titanic_df['Age']))\n",
    "\n",
    "# Step 3: Assess the impact of outlier handling\n",
    "fare_after_outliers = titanic_df[(titanic_df['Fare'] < fare_lower_bound) | (titanic_df['Fare'] > fare_upper_bound)]\n",
    "age_after_outliers = titanic_df[(titanic_df['Age'] < age_lower_bound) | (titanic_df['Age'] > age_upper_bound)]\n",
    "\n",
    "# Display results of outlier handling\n",
    "(len(fare_outliers), len(age_outliers)), (len(fare_after_outliers), len(age_after_outliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age     Fare  Age_standardized  Fare_standardized  Age_normalized  \\\n",
      "0  22.0   7.2500         -0.530377          -0.502445        0.271174   \n",
      "1  38.0  71.2833          0.571831           0.786845        0.472229   \n",
      "2  26.0   7.9250         -0.254825          -0.488854        0.321438   \n",
      "3  35.0  53.1000          0.365167           0.420730        0.434531   \n",
      "4  35.0   8.0500          0.365167          -0.486337        0.434531   \n",
      "\n",
      "   Fare_normalized  \n",
      "0         0.014151  \n",
      "1         0.139136  \n",
      "2         0.015469  \n",
      "3         0.103644  \n",
      "4         0.015713  \n"
     ]
    }
   ],
   "source": [
    "#CHECK!!!\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load the Titanic dataset\n",
    "file_path = '/Users/manuel/Desktop/DI-Bootcamp/Week4_PreProcessing_Data/D4/ExerciseXP/Titanic/train.csv'\n",
    "titanic_df = pd.read_csv(file_path)\n",
    "\n",
    "# Exercise 5: Data Standardization and Normalization\n",
    "\n",
    "# Step 1: Assess the scale and distribution of numerical columns\n",
    "# Select numerical columns for standardization and normalization\n",
    "numerical_cols = ['Age', 'Fare']\n",
    "\n",
    "# Step 2: Apply standardization to features with a wide range of values using StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "titanic_df[['Age_standardized', 'Fare_standardized']] = scaler_standard.fit_transform(titanic_df[numerical_cols])\n",
    "\n",
    "# Step 3: Apply normalization to features that require a bounded range [0, 1] using MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "titanic_df[['Age_normalized', 'Fare_normalized']] = scaler_minmax.fit_transform(titanic_df[numerical_cols])\n",
    "\n",
    "# Display the first few rows of the modified DataFrame\n",
    "print(titanic_df[['Age', 'Fare', 'Age_standardized', 'Fare_standardized', 'Age_normalized', 'Fare_normalized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin  Age_standardized  \\\n",
      "0      0         A/5 21171   7.2500   NaN         -0.530377   \n",
      "1      0          PC 17599  71.2833   C85          0.571831   \n",
      "2      0  STON/O2. 3101282   7.9250   NaN         -0.254825   \n",
      "3      0            113803  53.1000  C123          0.365167   \n",
      "4      0            373450   8.0500   NaN          0.365167   \n",
      "\n",
      "   Fare_standardized  Age_normalized  Fare_normalized  Embarked_C  Embarked_Q  \\\n",
      "0          -0.502445        0.271174         0.014151       False       False   \n",
      "1           0.786845        0.472229         0.139136        True       False   \n",
      "2          -0.488854        0.321438         0.015469       False       False   \n",
      "3           0.420730        0.434531         0.103644       False       False   \n",
      "4          -0.486337        0.434531         0.015713       False       False   \n",
      "\n",
      "   Embarked_S  Sex_encoded  \n",
      "0        True            1  \n",
      "1       False            0  \n",
      "2        True            0  \n",
      "3        True            0  \n",
      "4        True            1  \n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['Sex', 'Embarked']\n",
    "\n",
    "# Step 2: Use one-hot encoding for nominal variables\n",
    "# 'Embarked' is a nominal variable\n",
    "titanic_df = pd.get_dummies(titanic_df, columns=['Embarked'], prefix='Embarked')\n",
    "\n",
    "# Step 3: Use label encoding for ordinal variables\n",
    "# 'Sex' is a binary categorical variable, can use label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "titanic_df['Sex_encoded'] = label_encoder.fit_transform(titanic_df['Sex'])\n",
    "\n",
    "# Display the modified DataFrame with encoded features\n",
    "print(titanic_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age     AgeGroup  AgeGroup_Child  AgeGroup_Teenager  AgeGroup_Young Adult  \\\n",
      "0  22.0  Young Adult           False              False                  True   \n",
      "1  38.0        Adult           False              False                 False   \n",
      "2  26.0  Young Adult           False              False                  True   \n",
      "3  35.0  Young Adult           False              False                  True   \n",
      "4  35.0  Young Adult           False              False                  True   \n",
      "\n",
      "   AgeGroup_Adult  AgeGroup_Senior  \n",
      "0           False            False  \n",
      "1            True            False  \n",
      "2           False            False  \n",
      "3           False            False  \n",
      "4           False            False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "file_path = '/Users/manuel/Desktop/DI-Bootcamp/Week4_PreProcessing_Data/D4/ExerciseXP/Titanic/train.csv'\n",
    "titanic_df = pd.read_csv(file_path)\n",
    "\n",
    "# Exercise 7: Data Transformation for Age Feature\n",
    "\n",
    "# Step 1: Create age groups (bins) from the 'Age' column\n",
    "# Define age bins and corresponding labels\n",
    "age_bins = [0, 12, 18, 35, 60, 100]\n",
    "age_labels = ['Child', 'Teenager', 'Young Adult', 'Adult', 'Senior']\n",
    "\n",
    "# Use pd.cut() to categorize 'Age' into bins\n",
    "titanic_df['AgeGroup'] = pd.cut(titanic_df['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Step 2: Apply one-hot encoding to the age groups to convert them into binary features\n",
    "age_dummies = pd.get_dummies(titanic_df['AgeGroup'], prefix='AgeGroup')\n",
    "\n",
    "# Integrate the encoded features back into the main dataset\n",
    "titanic_df = pd.concat([titanic_df, age_dummies], axis=1)\n",
    "\n",
    "# Display the modified DataFrame with age groups and one-hot encoded features\n",
    "print(titanic_df[['Age', 'AgeGroup'] + list(age_dummies.columns)].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
